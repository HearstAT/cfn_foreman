---
AWSTemplateFormatVersion: '2010-09-09'
Description: "The Foreman on Ubuntu Xenial"
Parameters:
  VPC:
    Description: Choose VPC to use
    Type: AWS::EC2::VPC::Id
    Default: ''

  InstanceType:
    Type: String
    Default: t2.micro
    AllowedValues:
      - t2.nano
      - t2.micro
      - t2.small
      - t2.medium
      - m3.medium
      - m3.large
      - m3.xlarge
      - m3.2xlarge
      - c3.large
      - c3.xlarge
      - c3.2xlarge
      - c3.4xlarge
      - c3.8xlarge
      - c4.large
      - c4.xlarge
      - c4.2xlarge
      - c4.4xlarge
      - c4.8xlarge
      - g2.2xlarge
      - r3.large
      - r3.xlarge
      - r3.2xlarge
      - r3.4xlarge
      - r3.8xlarge
      - i2.xlarge
      - i2.2xlarge
      - i2.4xlarge
      - i2.8xlarge
      - d2.xlarge
      - d2.2xlarge
      - d2.4xlarge
      - d2.8xlarge
      - hi1.4xlarge
      - hs1.8xlarge
      - cr1.8xlarge
      - cc2.8xlarge
      - cg1.4xlarge
    ConstraintDescription: must be a valid EC2 instance type.

  KeyName:
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance
    Type: AWS::EC2::KeyPair::KeyName

  ChefBucketName:
    Type: String
    Default: ''
    Description: Enter name of Chef Bucket

  SSHSecurityGroup:
    Description: Select Security Group for SSH Access
    Type: AWS::EC2::SecurityGroup::Id
    Default: ''

  CIDRA:
    Type: String
    Default: 172.33.80.0/24
    Description: Subnet A CIDR Block

  CIDRB:
    Type: String
    Default: 172.33.90.0/24
    Description: Subnet B CIDR Block

  ForemanSubdomain:
    Type: String
    Default: foreman-a
    AllowedValues:
      - foreman-a
      - foreman-b
      - foreman-test
    Description: subdomain/prefix for chose hosted zone used for staging

  DBUser:
    Type: String
    Default: ''
    Description: Enter DB User Name

  DBPassword:
    Type: String
    NoEcho: 'true'
    Default: ''
    Description: Enter DB Password

  DBSnapShot:
    Type: String
    Default: ''
    Description: (Optional) Enter ARN of DB Snapshot to Create Database From

  AdminUser:
    Type: String
    Default: ''
    Description: Enter Foreman Admin User Name

  AdminEmail:
    Type: String
    Default: ''
    Description: Enter Foreman Admin Email

  AdminPassword:
    Type: String
    NoEcho: 'true'
    Default: ''
    Description: Enter Foreman Admin Password

  HostedZone:
    Type: String
    Default: domain.com
    Description: must match a route53 hosted domain/zone

  SSLCertificateARN:
    Type: String
    Default: ''
    Description: SSL Certficate ARN for SSL Certficate

  ChefServerUrl:
    Type: String
    Default: chef.domain.com
    Description: Enter the chef server url you wish to connect foreman to

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
    -
      Label:
        default: Instance & Network Configuration
      Parameters:
        - InstanceType
        - KeyName
        - VPC
        - HostedZone
        - SSLCertificateARN
        - SSHSecurityGroup
        - CIDRA
        - CIDRB
    -
      Label:
        default: Database Configuration
      Parameters:
        - DBUser
        - DBPassword
        - DBSnapShot
    -
      Label:
        default: Foreman Configuration
      Parameters:
        - AdminUser
        - AdminPassword
        - AdminEmail
        - ForemanSubdomain
    -
      Label:
        default: Chef Configuration
      Parameters:
        - ChefBucketName
        - ChefServerUrl

Mappings:
  RegionMap:
    us-west-2:
      HVM64: ami-efd0428f
    eu-west-1:
      HVM64: ami-a8d2d7ce

Resources:

###############################################################################
# Subnets
###############################################################################

  # Create the necessary subnets for Instance and DB
  SubnetA:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      # Get Availability Zones and select first in string
      AvailabilityZone: !Select [ 0, !GetAZs "" ]
      CidrBlock: !Ref CIDRA
      Tags:
        - Key: Name
          Value: Public-Subnet-A
        - Key: Application
          Value: !Ref AWS::StackId
        - Key: Network
          Value: "Public"

  SubnetB:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      # Get Availability Zones and select first in string
      AvailabilityZone: !Select [ 1, !GetAZs "" ]
      CidrBlock: !Ref CIDRB
      Tags:
        - Key: Name
          Value: Public-Subnet-B
        - Key: Application
          Value: !Ref AWS::StackId
        - Key: Network
          Value: "Public"

  # Create the necessary subnet for RDS PostgreSQL
  DBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: "Foreman DB Subnet Group"
      SubnetIds:
          - !Ref SubnetA
          - !Ref SubnetB
      Tags:

        - Key: Name
          Value: !Sub "${ForemanSubdomain} DB Subnet Group"

  ForemanDBSecurityGroup:
    Type: AWS::RDS::DBSecurityGroup
    Properties:
      EC2VpcId: !Ref VPC
      DBSecurityGroupIngress:
        - EC2SecurityGroupId: !Ref ServerSecurityGroup
      GroupDescription: "Frontend Access"

###############################################################################
# Security: IAM, Groups, Instance Profiles
###############################################################################

  ServerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Setup Ingress/Egress for Chef Frontend
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '80'
          ToPort: '80'
          SourceSecurityGroupId: !Ref ALBSecurityGroup
        - IpProtocol: tcp
          FromPort: '443'
          ToPort: '443'
          SourceSecurityGroupId: !Ref ALBSecurityGroup
        - IpProtocol: tcp
          FromPort: '443'
          ToPort: '9090'
          SourceSecurityGroupId: !Ref ALBSecurityGroup
        - IpProtocol: tcp
          FromPort: '80'
          ToPort: '9090'
          SourceSecurityGroupId: !Ref ALBSecurityGroup
        - IpProtocol: tcp
          FromPort: '22'
          ToPort: '22'
          SourceSecurityGroupId: !Ref SSHSecurityGroup
      SecurityGroupEgress:
        - IpProtocol: tcp
          FromPort: '0'
          ToPort: '65535'
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub ${ForemanSubdomain}-Frontend-Security-Group

  ALBSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Setup Ingress/Egress for Foreman Load Balancer
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '443'
          ToPort: '443'
          CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
        - IpProtocol: tcp
          FromPort: '0'
          ToPort: '65535'
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub ${ForemanSubdomain}-ALB-SecurityGroup

  InstanceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "ec2.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"

  RolePolicies:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: "root"
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Action: "s3:*"
            Resource: !Join [ "", [ "arn:aws:s3:::", !Ref ChefBucketName, "/*" ] ]
          -
            Effect: "Allow"
            Action: "s3:List*"
            Resource: "arn:aws:s3:::*"
      Roles:
        - !Ref InstanceRole

  InstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: "/"
      Roles:
        -
          !Ref InstanceRole

###############################################################################
# PostgreSQL DB
###############################################################################

  ForemanDB:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: !Sub ${ForemanSubdomain}-db
      DBName: "foreman_db"
      AllocatedStorage: 50
      DBInstanceClass:  db.t2.small
      AutoMinorVersionUpgrade: true
      Engine: "postgres"
      EngineVersion: "9.5.2"
      MasterUsername: !Ref DBUser
      MasterUserPassword: !Ref DBPassword
      BackupRetentionPeriod: "15"
      DBSnapshotIdentifier: !Ref DBSnapShot
      DBSecurityGroups:
        - !Ref ForemanDBSecurityGroup
      DBSubnetGroupName: !Ref DBSubnetGroup
      MonitoringInterval: 5
      Tags:
        - Key: Name
          Value: !Sub "${ForemanSubdomain} Database"
    DeletionPolicy: "Snapshot"

###############################################################################
# LoadBalancer and DNS
###############################################################################

  ForemanDNS:
    Type: AWS::Route53::RecordSetGroup
    Properties:
      HostedZoneName: !Sub "${HostedZone}."
      Comment: !Sub Zone apex alias targeted to ${ForemanSubdomain} ELB.
      RecordSets:
        - Name: !Join [ '', [ !Ref ForemanSubdomain, ".", !Ref HostedZone, "." ] ]
          Type: A
          AliasTarget:
            HostedZoneId: !GetAtt ForemanALB.CanonicalHostedZoneID
            DNSName: !GetAtt ForemanALB.DNSName

  ForemanALB:
    Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
    Properties:
      Name: !Sub ${ForemanSubdomain}-LB
      SecurityGroups:
        - Ref: ALBSecurityGroup
      Subnets:
        - Ref: SubnetA
        - Ref: SubnetB
      Tags:
        - Key: Name
          Value: !Sub "${ForemanSubdomain}-LB"

  ForemanALBListener:
    Type: "AWS::ElasticLoadBalancingV2::Listener"
    Properties:
        Certificates:
          - CertificateArn: !Ref SSLCertificateARN
        LoadBalancerArn: !Ref ForemanALB
        Port: 443
        Protocol: HTTPS
        DefaultActions:
            - Type: forward
              TargetGroupArn: !Ref ForemanTargetGroup

  ForemanTargetGroup:
      Type: "AWS::ElasticLoadBalancingV2::TargetGroup"
      Properties:
          Name: !Sub "${ForemanSubdomain}-TargetGroup"
          HealthCheckIntervalSeconds: 60
          UnhealthyThresholdCount: 10
          HealthCheckPath: /users/login
          VpcId: !Ref VPC
          Port: 80
          Protocol: HTTP

  ProxyDNS:
    Type: AWS::Route53::RecordSetGroup
    Properties:
      HostedZoneName: !Sub "${HostedZone}."
      Comment: !Sub Zone apex alias targeted to ${ForemanSubdomain} ELB.
      RecordSets:
        - Name: !Join [ '', [ !Ref ForemanSubdomain, "-proxy.", !Ref HostedZone, "." ] ]
          Type: A
          AliasTarget:
            HostedZoneId: !GetAtt ProxyALB.CanonicalHostedZoneID
            DNSName: !GetAtt ProxyALB.DNSName

  ProxyALB:
    Type: "AWS::ElasticLoadBalancingV2::LoadBalancer"
    Properties:
      Name: !Sub ${ForemanSubdomain}-Proxy-LB
      SecurityGroups:
        - Ref: ALBSecurityGroup
      Subnets:
        - Ref: SubnetA
        - Ref: SubnetB
      Tags:
        - Key: Name
          Value: !Sub "${ForemanSubdomain}-Proxy-LB"

  ProxyALBListener:
    Type: "AWS::ElasticLoadBalancingV2::Listener"
    Properties:
        Certificates:
          - CertificateArn: !Ref SSLCertificateARN
        LoadBalancerArn: !Ref ProxyALB
        Port: 443
        Protocol: HTTPS
        DefaultActions:
            - Type: forward
              TargetGroupArn: !Ref ProxyTargetGroup

  ProxyTargetGroup:
      Type: "AWS::ElasticLoadBalancingV2::TargetGroup"
      Properties:
          Name: !Sub "${ForemanSubdomain}-Proxy-TargetGroup"
          HealthCheckIntervalSeconds: 60
          UnhealthyThresholdCount: 10
          HealthCheckPath: /features
          VpcId: !Ref VPC
          Port: 8443
          Protocol: HTTPS

###############################################################################
# Autoscaling
###############################################################################

  BootstrapAutoScaleGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    DependsOn:
      - ForemanDB
    Properties:
      AvailabilityZones:
        - !Select [ 0, !GetAZs "" ]
        - !Select [ 1, !GetAZs "" ]
      VPCZoneIdentifier:
        - !Ref SubnetA
        - !Ref SubnetB
      LaunchConfigurationName: !Ref ServerLaunchConfig
      TargetGroupARNs:
        - !Ref ForemanTargetGroup
        - !Ref ProxyTargetGroup
      MaxSize: '1'
      MinSize: '1'
      Tags:
      - Key: Name
        Value: !Sub ${ForemanSubdomain}-${AWS::StackName}
        PropagateAtLaunch: true

###############################################################################
# Instance Launch Configuration
###############################################################################

  ServerLaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Properties:
      ImageId: !FindInMap [ RegionMap, !Ref "AWS::Region", HVM64 ]
      InstanceType: !Ref InstanceType
      KeyName: !Ref KeyName
      AssociatePublicIpAddress: true
      SecurityGroups:
        - !Ref ServerSecurityGroup
        - !Ref SSHSecurityGroup
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: 20
            VolumeType: gp2
            DeleteOnTermination: true
      IamInstanceProfile: !Ref InstanceProfile
      UserData:
        "Fn::Base64":
          "Fn::Sub":
            - |
              #!/bin/bash -xev

              ##########################################################
              # Global Variable Set
              ##########################################################

              export DEBIAN_FRONTEND=noninteractive
              export INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
              export STACKNAME='${AWS::StackName}'
              export HOSTNAME="${ForemanSubdomain}.${HostedZone}"

              ##########################################################
              # Upgrade OS & Install Dependencies
              ##########################################################

              apt-get update && apt-get -y upgrade
              apt-get install -y wget curl python-setuptools python-pip git ca-certificates ruby ruby-dev libvirt-dev libaugeas-dev puppet

              ##########################################################
              # Install AWS & CFN Tools
              ##########################################################

              if [ -z $(command -v cfn-signal) ]; then
                  easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
              fi

              if [ -z $(command -v aws) ]; then
                sleep 5
                pip install awscli
              fi

              ##########################################################
              # Install cfn bootstraping tools
              ##########################################################

              if [ -z $(command -v cfn-signal) ]; then
                  easy_install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
              fi

              ##########################################################
              # Helper function to set wait timer
              ##########################################################

              error_exit()
              {
                cfn-signal -e 1 -r "$1" "${WaitHandle}"
                exit 1
              }

              export -f error_exit

              ##########################################################
              # Get Chef Data
              ##########################################################

              if [ ! -d "/etc/opscode" ]; then
                mkdir /etc/opscode
              fi

              aws s3 cp s3://${ChefBucketName}/etc_opscode/pivotal.pem /etc/opscode || error_exit "Failed to sync existing Pivotal Key"

              chown -R root:root /etc/opscode/ && chmod -R 766 /etc/opscode

              ##########################################################
              # Set Hostname and Hosts File
              ##########################################################

              hostname ${ForemanSubdomain}.${HostedZone}  || error_exit 'Failed to set hostname'
              echo  ${ForemanSubdomain}.${HostedZone}  > /etc/hostname || error_exit 'Failed to set hostname file'

              cat > '/etc/hosts' << EOF
              127.0.0.1 ${ForemanSubdomain}-proxy.${HostedZone} ${ForemanSubdomain}-proxy localhost
              ::1 localhost6.localdomain6 localhost6
              EOF

              ##########################################################
              # Install Foreman Repo
              ##########################################################

              echo "deb http://deb.theforeman.org/ xenial 1.14" > /etc/apt/sources.list.d/theforeman.list || error_exit "Failed to add foreman repo"
              echo "deb http://deb.theforeman.org/ plugins 1.14" >> /etc/apt/sources.list.d/theforeman.list || error_exit "Failed to plugins repo"
              wget -q https://deb.theforeman.org/pubkey.gpg -O- | apt-key add - || error_exit "failed to add gpg key for repos"
              apt-get update && apt-get -y install foreman-installer || error_exit "Failed to install foreman-installed"

              ##########################################################
              # Create Local Certs
              ##########################################################

              if [ ! -d /opt/certs ]; then
                mkdir -p /opt/certs
              fi

              cat > '/etc/puppet/puppet.conf' << EOF
              [main]
              logdir=/var/log/puppet
              vardir=/var/lib/puppet
              ssldir=/opt/certs
              rundir=/run/puppet
              factpath=$vardir/lib/facter
              prerun_command=/etc/puppet/etckeeper-commit-pre
              postrun_command=/etc/puppet/etckeeper-commit-post

              [master]
              # These are needed when the puppetmaster is run by passenger
              # and can safely be removed if webrick is used.
              ssl_client_header = SSL_CLIENT_S_DN
              ssl_client_verify_header = SSL_CLIENT_VERIFY
              EOF

              if [ ! -f "/opt/certs/${ForemanSubdomain}.${HostedZone}.pem" ]; then
                puppet cert generate ${ForemanSubdomain}.${HostedZone} || error_exit "Failed to generate cert for Foreman"
              fi

              if [ ! -f "/opt/certs/${ForemanSubdomain}-proxy.${HostedZone}.pem" ]; then
                puppet cert generate ${ForemanSubdomain}-proxy.${HostedZone} || error_exit "Failed to generate cert for Foreman Proxy"
              fi
              ## Future Config
              # aws s3 sync /opt/certs s3://${!FOREMANBUCKET}/certs || error_exit "Failed to sync bootstrap foreman directory"

              ##########################################################
              # Foreman Answer File
              ##########################################################

              mkdir -p /etc/foreman-installer/scenarios.d/ || error_exit "Could create foreman answers directory"

              cat > '/etc/foreman-installer/scenarios.d/foreman-answers.yaml' <<EOF
              ---
                foreman:
                  foreman_url: "https://${ForemanSubdomain}.${HostedZone}"
                  locations_enabled: true
                  organizations_enabled: true
                  puppetrun: false
                  unattended: true
                  authentication: true
                  passenger: true
                  passenger_ruby: /usr/bin/foreman-ruby
                  passenger_ruby_package:
                  servername: ${ForemanSubdomain}.${HostedZone}
                  serveraliases:
                    - foreman
                    - ${ForemanSubdomain}
                  ssl: false
                  custom_repo: true
                  repo: stable
                  gpgcheck: true
                  db_manage: false
                  db_type: postgresql
                  db_adapter: postgresql
                  db_host: ${DBENDPOINT}
                  db_port: ${DBPORT}
                  db_database: foreman_db
                  db_username: ${DBUser}
                  db_password: ${DBPassword}
                  app_root: /usr/share/foreman
                  manage_user: true
                  user: foreman
                  group: foreman
                  user_groups:
                    - puppet
                  rails_env: production
                  puppet_home: /var/lib/puppet
                  puppet_ssldir: /opt/certs/
                  server_ssl_port: 443
                  server_ssl_chain: /opt/certs/ca.pem
                  server_ssl_cert: /opt/certs/${ForemanSubdomain}.${HostedZone}.pem
                  server_ssl_certs_dir: /opt/certs/
                  server_ssl_key: /opt/certs/private_keys/${ForemanSubdomain}.${HostedZone}.pem
                  server_ssl_crl: ""
                  client_ssl_ca: /opt/certs/ca.pem
                  client_ssl_cert: /opt/certs/${ForemanSubdomain}.${HostedZone}.pem
                  client_ssl_key: /opt/certs/private_keys/${ForemanSubdomain}.${HostedZone}.pem
                  admin_username: ${AdminUser}
                  admin_password: ${AdminPassword}
                  admin_email: ${AdminEmail}
                  websockets_encrypt: true
                  websockets_ssl_key: /opt/certs/private_keys/${ForemanSubdomain}.${HostedZone}.pem
                  websockets_ssl_cert: /opt/certs/${ForemanSubdomain}.${HostedZone}.pem
                  email_conf: email.yaml
                  email_source: email.yaml.erb
                  email_delivery_method:
                  email_smtp_address:
                  email_smtp_port: 25
                  email_smtp_domain:
                  email_smtp_authentication: none
                  email_smtp_user_name:
                  email_smtp_password:
                "foreman::cli":
                  foreman_url:
                  manage_root_config: true
                  username:
                  password:
                  refresh_cache: false
                  request_timeout: 120
                foreman_proxy:
                  bind_host: "*"
                  ssl_port: 8443
                  gpgcheck: true
                  custom_repo: true
                  http: false
                  ssl: true
                  ssl_ca: /opt/certs/ca.pem
                  ssl_cert: /opt/certs/${ForemanSubdomain}-proxy.${HostedZone}.pem
                  ssl_key: /opt/certs/private_keys/${ForemanSubdomain}-proxy.${HostedZone}.pem
                  foreman_ssl_ca: /opt/certs/ca.pem
                  foreman_ssl_cert: /opt/certs/${ForemanSubdomain}.${HostedZone}.pem
                  foreman_ssl_key: /opt/certs/private_keys/${ForemanSubdomain}.${HostedZone}.pem
                  trusted_hosts:
                    - foreman.${HostedZone}
                    - ${ForemanSubdomain}.${HostedZone}
                    - ${ForemanSubdomain}-proxy.${HostedZone}
                  logs: true
                  logs_listen_on: https
                  tftp: true
                  tftp_listen_on: https
                  register_in_foreman: false
                  ssl_disabled_ciphers: []
                  manage_sudoersd: true
                  use_sudoersd: true
                  puppetca: false
                  manage_puppet_group: false
                  puppet: false
                  foreman_base_url: "https://${ForemanSubdomain}.${HostedZone}"
                  registered_name: ${ForemanSubdomain}-proxy.${HostedZone}
                  registered_proxy_url: https://${ForemanSubdomain}-proxy.${HostedZone}:8443
                puppet: false
                "foreman::plugin::tasks":
                  package: ruby-foreman-tasks
                  service: ruby-foreman-tasks
                "foreman::compute::ec2": true
                "foreman::plugin::chef": true
                "foreman_proxy::plugin::chef":
                  enabled: true
                  listen_on: https
                  server_url: ${ChefServerUrl}
                  client_name: pivotal
                  private_key: /etc/opscode/pivotal.pem
                  ssl_verify: true
              EOF

              foreman-installer || error_exit "Foreman Install Failed"
              # Run foremand DB tasks
              foreman-rake db:migrate || error_exit "db migrate failed for Foreman"
              if [ -z ${DBSnapShot} ]; then
                foreman-rake db:seed || error_exit "db seed failed for Foreman"
              fi
              foreman-rake apipie:cache:index || error_exit "apipie cache index failed for foreman"

              service apache2 restart || error_exit "Failed to restart foreman post DB Setup"

              # All is well so signal success and let CF know wait function is complete
              cfn-signal -e 0 -r 'Server setup complete' "${WaitHandle}"
            - { DBENDPOINT: !GetAtt [ ForemanDB, Endpoint.Address ], DBPORT: !GetAtt [ ForemanDB, Endpoint.Port ], FOREMANURL: !Join [ '', [ !Ref ForemanSubdomain, ".", !Ref HostedZone ] ] }

  # Wait setups to force EC2 instances to now show cloudformation complete until the Userdata (backend cookbook) has completely succesfully
  WaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle
  WaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    DependsOn: ServerLaunchConfig
    Properties:
      Handle:  !Ref WaitHandle
      Timeout: '2300'
